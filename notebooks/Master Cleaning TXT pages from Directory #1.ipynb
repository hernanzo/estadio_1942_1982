{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d5141a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/hernanadasme/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/hernanadasme/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b9c1a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6573ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_1(text):\n",
    "    text = text.replace('\\n', '')\n",
    "    pattern_1 = r'[^\\w\\sáéíóúüÁÉÍÓÚÜ]'\n",
    "    # Replace the special characters with an empty string\n",
    "    text = re.sub(pattern_1, '', text)\n",
    "    return text\n",
    "\n",
    "def function_2(text):\n",
    "    #add a space before uppercase\n",
    "    text = re.sub(r'([A-Z])', r' \\1', text).strip()\n",
    "    #add a space before and after a digit\n",
    "    text = re.sub(r'(\\d)', r' \\1 ', text) \n",
    "    return text\n",
    "\n",
    "def function_3(text):\n",
    "    word_list = [\"Chile\", \"chilenos\", \"muy\", 'hombres', \"norteamericano\", \"chileno\", \"chilenas\", \"Argentina\", \"argentino\", \"argentinos\", \"argentinas\"]\n",
    "    pattern = fr'({\"|\".join(word_list)})'\n",
    "    text = re.sub(pattern, r' \\1 ', text)\n",
    "    return text \n",
    "\n",
    "def function_4(text):\n",
    "    tokens_englow = ['elgoal', 'ranking', 'match', 'forward', 'players','field', 'back', 'pitchers', 'winger', 'shot','shoot','handicap','kick','second','referee','insider','crack','standard','jersey','knockout','out','record','score','single','sport','shortstop','training','centerforward','sprinter']\n",
    "    pattern = fr'({\"|\".join(tokens_englow)})'\n",
    "    text = re.sub(pattern, r' \\1 ', text)\n",
    "    return text\n",
    "\n",
    "def function_5(text):\n",
    "    tokens_engup = ['elgoal', 'Ranking', 'Match', 'Forward', 'Players','Field', 'Back', 'Pitchers', 'Winger', 'Shot','Shoot','Handicap','Kick','Second','Referee','Insider','Crack','Standard','Jersey','Knockout','Out','Record','Score','Single','Sport','Shortstop','Training','Centerforward','Sprinter']\n",
    "    pattern = fr'({\"|\".join(tokens_engup)})'\n",
    "    text = re.sub(pattern, r' \\1 ', text)\n",
    "    return text\n",
    "\n",
    "def function_6(text):\n",
    "    tokens_esplow = ['gol', 'equipo','partido','delantero','cancha','defensa','lanzador','lateral','disparo','disparar','jugador','desventaja','patear','segundo','juez','interior','estrella','estandar','camiseta','falta','nocaut','fuera','registro','marcador','individual','deporte','parada','entrenamiento','centrodelantero','velocista']\n",
    "    pattern = fr'({\"|\".join(tokens_esplow)})'\n",
    "    text = re.sub(pattern, r' \\1 ', text)\n",
    "    return text\n",
    "\n",
    "def function_7(text):\n",
    "    tokens_englow = ['Gol', 'Equipo','Partido', 'Muy', 'Delantero', 'Cancha', 'Defensa', 'Lanzador', 'Lateral', 'Disparo', 'Disparar', 'Jugador', 'Desventaja', 'Patear', 'Segundo', 'Juez', 'Interior', 'Estrella', 'Estandar', 'Camiseta', 'Falta', 'Nocaut', 'Fuera', 'Registro', 'Marcador', 'Individual', 'Deporte', 'Parada', 'Entrenamiento', 'Centrodelantero', 'Velocista']\n",
    "    pattern = fr'({\"|\".join(tokens_englow)})'\n",
    "    text = re.sub(pattern, r' \\1 ', text)\n",
    "    return text\n",
    "\n",
    "def function_8(text):\n",
    "    word_list = ['están', \"ahí\", \"hay\", 'así','actuó', 'buscó', 'sí', \"allá\", \"habían\", \"sólo\", \"llegó\", \"después\", \"más\", \"siempre\", \"hasta\", \"también\", \"mañana\",\"sé\",\"dejó\", \"sus\", \"éste\", \"ningún\", \"podrá\", \"tendrá\", \"además\", \"través\", \"fué\", \"fútbol\", \"esté\"]\n",
    "    pattern = fr'({\"|\".join(word_list)})'\n",
    "    text = re.sub(pattern, r' \\1 ', text)\n",
    "    return text\n",
    "\n",
    "def function_9(text):\n",
    "    word_list = ['Están', 'Ahí', 'Hay', 'Habían', 'Sólo', 'él', 'Él', 'perdió','Después', 'Más', 'Siempre', 'Hasta', 'También', 'Mañana', 'Sé', 'Dejó', 'Sus', 'Éste', 'Podrá', 'Tendrá', 'Además', 'Través', 'Fútbol']\n",
    "    pattern = fr'({\"|\".join(word_list)})'\n",
    "    text = re.sub(pattern, r' \\1 ', text)\n",
    "    return text \n",
    "\n",
    "def function_10(text):\n",
    "    word_list = ['Diez', 'diez', 'Veinte', 'veinte', 'Treinta', 'Cuarenta', 'cuarenta', 'cincuenta', 'Cincuenta', 'sesenta', 'Sesenta', 'Setenta', 'setenta','ochenta', 'Ochenta', 'noventa', 'Noventa']\n",
    "    pattern = fr'({\"|\".join(word_list)})'\n",
    "    text = re.sub(pattern, r' \\1 ', text)\n",
    "    return text\n",
    "\n",
    "def function_11(text):\n",
    "    word_list = ['tres', 'Tres', 'cuatro', 'Cuatro', 'cinco', 'Cinco', 'seis', 'Seis', 'siete', 'Siete', 'ocho', 'Ocho', 'nueve', 'Nueve']\n",
    "    pattern = fr'({\"|\".join(word_list)})'\n",
    "    text = re.sub(pattern, r' \\1 ', text)\n",
    "    return text\n",
    "\n",
    "#removing digits\n",
    "def function_12(text): \n",
    "    pattern = r'\\d+'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "#lowercase text\n",
    "def function_13(text):\n",
    "    text = text.lower()\n",
    "    return text\n",
    "#removing isolated letters\n",
    "def function_14(text):\n",
    "    text = text.split()\n",
    "    text = [word for word in text if len(word) > 1]\n",
    "    # Join the filtered words back into a string\n",
    "    text = \" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd9c0447",
   "metadata": {},
   "outputs": [],
   "source": [
    "#master function to run it all\n",
    "def master_function(input_string):\n",
    "    # Define a list of functions to apply\n",
    "    function_list = [function_1, function_2, function_3, function_4, function_5, function_6, function_7, function_8, function_9, function_10, function_11, function_12, function_13, function_14]\n",
    "\n",
    "    # Apply each function in the list to the input string\n",
    "    for function in function_list:\n",
    "        input_string = function(input_string)\n",
    "\n",
    "    # Return the final result\n",
    "    return input_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64f90bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_txt(txt_dir, clean_txt_dir):\n",
    "    for filename in os.listdir(txt_dir):\n",
    "        if filename.endswith('.txt'):\n",
    "            filepath = os.path.join(txt_dir, filename)\n",
    "            with open(filepath, 'r') as f:\n",
    "                text = f.read()\n",
    "            cleaned_text = master_function(text)\n",
    "            cleaned_filepath = os.path.join(clean_txt_dir, filename)\n",
    "            with open(cleaned_filepath, 'w') as f:\n",
    "                f.write(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee7daaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_path = r'/Users/hernanadasme/Projects/estadio_1940_1980/estadio_txt/1980_1982'\n",
    "clean_txt_path = r'/Users/hernanadasme/Projects/estadio_1940_1980/estadio_txt/cleaned_notebook_1980_1982'\n",
    "clean_txt(text_path, clean_txt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadf1018",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
